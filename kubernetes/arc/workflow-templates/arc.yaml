apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: arc
spec:
  templates:
  - name: arc
    inputs:
      # override defaults here
      parameters:
      - name: configUri
      - name: image
        value: triplai/arc:arc_3.2.0_spark_3.0.0_scala_2.12_hadoop_3.2.0_1.0.0
      - name: driverCores
        value: 1
      - name: driverMemory
        value: 1G
      - name: executorInstances
        value: 1
      - name: executorCores
        value: 1
      - name: executorMemory
        value: 1G
      - name: pullPolicy
        value: Always
      - name: sparkConf
        value: ""
      - name: tags
        value: ""
      - name: parameters
        value: ""
    metadata:
      labels:
        workflowId: "{{workflow.uid}}"
    script:
      image: "{{inputs.parameters.image}}"
      env:
      - name: ETL_CONF_ENV
        value: "{{workflow.namespace}}"
      command: ["/bin/sh"]
      source: |
        # verbose logging
        set -ex

        # print current hostname and ip
        hostname
        hostname -I

        # submit job
        bin/spark-submit \
        --master k8s://kubernetes.default.svc:443 \
        --deploy-mode client \
        --class ai.tripl.arc.ARC \
        --name arc \
        --conf spark.authenticate=true \
        --conf spark.blockManager.port=7079 \
        --conf spark.driver.extraJavaOptions="-XX:+UseG1GC" \
        --conf spark.driver.host=$(hostname -I)  \
        --conf spark.driver.memory={{inputs.parameters.driverMemory}} \
        --conf spark.driver.pod.name=$(hostname) \
        --conf spark.driver.port=7078 \
        --conf spark.executor.cores={{inputs.parameters.executorCores}} \
        --conf spark.executor.extraJavaOptions="-XX:+UseG1GC" \
        --conf spark.executor.instances={{inputs.parameters.executorInstances}} \
        --conf spark.executor.memory={{inputs.parameters.executorMemory}} \
        --conf spark.io.encryption.enabled=true \
        --conf spark.kubernetes.authenticate.caCertFile=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt \
        --conf spark.kubernetes.authenticate.driver.serviceAccountName={{workflow.serviceAccountName}} \
        --conf spark.kubernetes.authenticate.oauthTokenFile=/var/run/secrets/kubernetes.io/serviceaccount/token \
        --conf spark.kubernetes.container.image.pullPolicy={{inputs.parameters.pullPolicy}} \
        --conf spark.kubernetes.container.image={{inputs.parameters.image}} \
        --conf spark.kubernetes.driver.limit.cores={{inputs.parameters.driverCores}} \
        --conf spark.kubernetes.driver.pod.name=$(hostname) \
        --conf spark.kubernetes.executor.label.workflowId={{workflow.uid}} \
        --conf spark.kubernetes.executor.limit.cores={{inputs.parameters.executorCores}} \
        --conf spark.kubernetes.executor.podNamePrefix=$(hostname)-spark \
        --conf spark.kubernetes.executor.request.cores={{inputs.parameters.executorCores}} \
        --conf spark.kubernetes.local.dirs.tmpfs=false \
        --conf spark.kubernetes.namespace={{workflow.namespace}} \
        --conf spark.network.crypto.enabled=true \
        --conf spark.ui.enabled=true \
        --conf spark.sql.cbo.enabled=false \
        --conf spark.sql.adaptive.enabled=false \
        {{inputs.parameters.sparkConf}} \
        local:///opt/spark/jars/arc.jar \
        --etl.config.uri={{inputs.parameters.configUri}} \
        --etl.config.tags="workflowId={{workflow.uid}} serviceAccount={{workflow.serviceAccountName}} namespace={{workflow.namespace}} {{inputs.parameters.tags}}" \
        {{inputs.parameters.parameters}}